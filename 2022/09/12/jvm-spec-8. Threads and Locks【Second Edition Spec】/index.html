<!DOCTYPE html><html class="appearance-auto" lang="zh-CN"><head><meta charset="UTF-8"><title>jvm-spec-8. Threads and Locks【Second Edition Spec】</title><meta name="description" content="Let's go"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="https://zincv.oss-cn-hangzhou.aliyuncs.com/IMG_1541.jpg"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><link rel="stylesheet" href="/style/common/jquery.fancybox.min.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="This chapter details the low-level actions that may be used to explain the interaction of Java virtual machine threads with a shared main memory. It has been adapted with minimal changes from Chapter 17 of the first edition of _The Java_TM Language Specification, by James Gosling, Bill Joy, and Guy Steele.

8.1 Terminology and FrameworkA variable is any lo.."><meta name="generator" content="Hexo 7.3.0"></head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Zhangdd's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">jvm-spec-8. Threads and Locks【Second Edition Spec】</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">点击返回顶部</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#8-1-Terminology-and-Framework"><span class="toc-text">8.1 Terminology and Framework</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-2-Execution-Order-and-Consistency"><span class="toc-text">8.2 Execution Order and Consistency</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-3-Rules-About-Variables"><span class="toc-text">8.3 Rules About Variables</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-4-Nonatomic-Treatment-of-double-and-long-Variables"><span class="toc-text">8.4 Nonatomic Treatment of double and long Variables</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-5-Rules-About-Locks"><span class="toc-text">8.5 Rules About Locks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-6-Rules-About-the-Interaction-of-Locks-and-Variables"><span class="toc-text">8.6 Rules About the Interaction of Locks and Variables</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-7-Rules-for-volatile-Variables"><span class="toc-text">8.7 Rules for volatile Variables</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-8-Prescient-Store-Operations"><span class="toc-text">8.8 Prescient Store Operations</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-9-Discussion"><span class="toc-text">8.9 Discussion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-10-Example-Possible-Swap"><span class="toc-text">8.10 Example: Possible Swap</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-11-Example-Out-of-Order-Writes"><span class="toc-text">8.11 Example: Out-of-Order Writes</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-12-Threads"><span class="toc-text">8.12 Threads</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-13-Locks-and-Synchronization"><span class="toc-text">8.13 Locks and Synchronization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-14-Wait-Sets-and-Notification"><span class="toc-text">8.14 Wait Sets and Notification</span></a></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E7%BF%BB%E8%AF%91"><i class="tag post-item-tag">官方文档翻译</i></a><a href="/tags/jvm"><i class="tag post-item-tag">jvm</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">jvm-spec-8. Threads and Locks【Second Edition Spec】</h1><time class="has-text-grey" datetime="2022-09-12T14:46:49.000Z">2022-09-12</time><article class="mt-2 post-content"><p>This chapter details the low-level actions that may be used to explain the interaction of Java virtual machine threads with a shared main memory. It has been adapted with minimal changes from Chapter 17 of the first edition of _The Java_TM <em>Language Specification</em>, by James Gosling, Bill Joy, and Guy Steele.</p>
<hr>
<h2 id="8-1-Terminology-and-Framework"><a href="#8-1-Terminology-and-Framework" class="headerlink" title="8.1 Terminology and Framework"></a>8.1 Terminology and Framework</h2><p>A <em>variable</em> is any location within a program that may be stored into. This includes not only class variables and instance variables, but also components of arrays. Variables are kept in a <em>main memory</em> that is shared by all threads. Because it is impossible for one thread to access parameters or local variables of another thread, it does not matter whether parameters and local variables are thought of as residing in the shared main memory or in the working memory of the thread that owns them.</p>
<p>Every thread has a <em>working memory</em> in which it keeps its own <em>working copy</em> of variables that it must use or assign. As the thread executes a program, it operates on these working copies. The main memory contains the _master copy_of every variable. There are rules about when a thread is permitted or required to transfer the contents of its working copy of a variable into the master copy or vice versa.</p>
<p>The main memory also contains <em>locks</em>; there is one lock associated with each object. Threads may compete to acquire a lock.</p>
<p>For the purposes of this chapter, the verbs <em>use</em>, <em>assign</em>, <em>load</em>, <em>store</em>, <em>lock</em>, and <em>unlock</em> name actions that a thread can perform. The verbs <em>read</em>, <em>write</em>, <em>lock</em>, and <em>unlock</em> name actions that the main memory subsystem can perform. Each of these operations is atomic (indivisible). </p>
<p>A <em>use</em> or <em>assign</em> operation is a tightly coupled interaction between a thread’s execution engine and the thread’s working memory. A <em>lock</em> or <em>unlock</em> operation is a tightly coupled interaction between a thread’s execution engine and the main memory. But the transfer of data between the main memory and a thread’s working memory is loosely coupled. When data is copied from the main memory to a working memory, two actions must occur: a <em>read</em> operation performed by the main memory, followed some time later by a corresponding <em>load</em> operation performed by the working memory. When data is copied from a working memory to the main memory, two actions must occur: a _store_operation performed by the working memory, followed some time later by a corresponding <em>write</em> operation performed by the main memory. There may be some transit time between main memory and a working memory, and the transit time may be different for each transaction; thus, operations initiated by a thread on different variables may be viewed by another thread as occurring in a different order. For each variable, however, the operations in main memory on behalf of any one thread are performed in the same order as the corresponding operations by that thread. (This is explained in greater detail later.)</p>
<p>A single thread issues a stream of <em>use</em>, <em>assign</em>, <em>lock</em>, and <em>unlock</em> operations as dictated by the semantics of the program it is executing. The underlying Java virtual machine implementation is then required additionally to perform appropriate <em>load</em>, <em>store</em>, <em>read</em>, and <em>write</em> operations so as to obey a certain set of constraints, explained later. If the implementation correctly follows these rules and the programmer follows certain other rules of programming, then data can be reliably transferred between threads through shared variables. The rules are designed to be “tight” enough to make this possible, but “loose” enough to allow hardware and software designers considerable freedom to improve speed and throughput through such mechanisms as registers, queues, and caches.</p>
<p>Here are the detailed definitions of each of the operations:</p>
<ul>
<li><p>A <em>use</em> action (by a thread) transfers the contents of the thread’s working copy of a variable to the thread’s execution engine. This action is performed whenever a thread executes a virtual machine instruction that uses the value of a variable.</p>
</li>
<li><p>An <em>assign</em> action (by a thread) transfers a value from the thread’s execution engine into the thread’s working copy of a variable. This action is performed whenever a thread executes a virtual machine instruction that assigns to a variable.</p>
</li>
<li><p>A <em>read</em> action (by the main memory) transmits the contents of the master copy of a variable to a thread’s working memory for use by a later <em>load</em> operation.</p>
</li>
<li><p>A <em>load</em> action (by a thread) puts a value transmitted from main memory by a <em>read</em> action into the thread’s working copy of a variable.</p>
</li>
<li><p>A <em>store</em> action (by a thread) transmits the contents of the thread’s working copy of a variable to main memory for use by a later <em>write</em> operation.</p>
</li>
<li><p>A <em>write</em> action (by the main memory) puts a value transmitted from the thread’s working memory by a <em>store</em> action into the master copy of a variable in main memory.</p>
</li>
<li><p>A <em>lock</em> action (by a thread tightly synchronized with main memory) causes a thread to acquire one claim on a particular lock.</p>
</li>
<li><p>An <em>unlock</em> action (by a thread tightly synchronized with main memory) causes a thread to release one claim on a particular lock.</p>
</li>
</ul>
<p>Thus, the interaction of a thread with a variable over time consists of a sequence of <em>use</em>, <em>assign</em>, <em>load</em>, and <em>store</em> operations. Main memory performs a <em>read</em> operation for every <em>load</em> and a <em>write</em> operation for every <em>store</em>. A thread’s interactions with a lock over time consist of a sequence of <em>lock</em> and <em>unlock</em> operations. All the globally visible behavior of a thread thus comprises all the thread’s operations on variables and locks.</p>
<hr>
<h2 id="8-2-Execution-Order-and-Consistency"><a href="#8-2-Execution-Order-and-Consistency" class="headerlink" title="8.2 Execution Order and Consistency"></a>8.2 Execution Order and Consistency</h2><p>The rules of execution order constrain the order in which certain events may occur. There are four general constraints on the relationships among actions:</p>
<ul>
<li><p>The actions performed by any one thread are totally ordered; that is, for any two actions performed by a thread, one action precedes the other.</p>
</li>
<li><p>The actions performed by the main memory for any one variable are totally ordered; that is, for any two actions performed by the main memory on the same variable, one action precedes the other.</p>
</li>
<li><p>The actions performed by the main memory for any one lock are totally ordered; that is, for any two actions performed by the main memory on the same lock, one action precedes the other.</p>
</li>
<li><p>It is not permitted for an action to follow itself.</p>
</li>
</ul>
<p>The last rule may seem trivial, but it does need to be stated separately and explicitly for completeness. Without the rule, it would be possible to propose a set of actions by two or more threads and precedence relationships among the actions that would satisfy all the other rules but would require an action to follow itself.</p>
<p>Threads do not interact directly; they communicate only through the shared main memory. The relationships between the actions of a thread and the actions of main memory are constrained in three ways: </p>
<ul>
<li><p>Each <em>lock</em> or <em>unlock</em> action is performed jointly by some thread and the main memory.</p>
</li>
<li><p>Each <em>load</em> action by a thread is uniquely paired with a <em>read</em> action by the main memory such that the <em>load</em> action follows the <em>read</em> action.</p>
</li>
<li><p>Each <em>store</em> action by a thread is uniquely paired with a <em>write</em> action by the main memory such that the <em>write</em> action follows the <em>store</em> action.</p>
</li>
</ul>
<p>Most of the rules in the following sections further constrain the order in which certain actions take place. A rule may state that one action must precede or follow some other action. Note that this relationship is transitive: if action _A_must precede action <em>B</em>, and <em>B</em> must precede <em>C</em>, then <em>A</em> must precede <em>C</em>. The programmer must remember that these rules are the <em>only</em> constraints on the ordering of actions; if no rule or combination of rules implies that action <em>A</em> must precede action <em>B</em>, then a Java virtual machine implementation is free to perform action <em>B</em> before action <em>A</em>, or to perform action <em>B</em> concurrently with action <em>A</em>. This freedom can be the key to good performance. Conversely, an implementation is not required to take advantage of all the freedoms given it.</p>
<p>In the rules that follow, the phrasing “<em>B</em> must intervene between <em>A</em> and <em>C</em>“ means that action <em>B</em> must follow action <em>A</em> and precede action <em>C</em>.</p>
<hr>
<h2 id="8-3-Rules-About-Variables"><a href="#8-3-Rules-About-Variables" class="headerlink" title="8.3 Rules About Variables"></a>8.3 Rules About Variables</h2><p>Let <em>T</em> be a thread and <em>V</em> be a variable. There are certain constraints on the operations performed by <em>T</em> with respect to <em>V</em>  :</p>
<ul>
<li><p>A <em>use</em> or <em>assign</em> by <em>T</em> of <em>V</em> is permitted only when dictated by execution by <em>T</em> of the program according to the standard execution model. For example, an occurrence of <em>V</em> as an operand of the <code>+</code> operator requires that a single <em>use</em> operation occur on <em>V</em>  ; an occurrence of <em>V</em> as the left-hand operand of the assignment operator <code>=</code> requires that a single <em>assign</em> operation occur. All <em>use</em> and <em>assign</em> actions by a given thread must occur in the order specified by the program being executed by the thread. If the following rules forbid <em>T</em> to perform a required <em>use</em> as its next action, it may be necessary for <em>T</em> to perform a <em>load</em> first in order to make progress.</p>
</li>
<li><p>A <em>store</em> operation by <em>T</em> on <em>V</em> must intervene between an <em>assign</em> by <em>T</em> of <em>V</em> and a subsequent <em>load</em> by <em>T</em> of <em>V</em>. (Less formally: a thread is not permitted to lose the most recent assign.)</p>
</li>
<li><p>An <em>assign</em> operation by <em>T</em> on <em>V</em> must intervene between a <em>load</em> or <em>store</em> by <em>T</em> of <em>V</em> and a subsequent <em>store</em> by <em>T</em> of <em>V</em>. (Less formally: a thread is not permitted to write data from its working memory back to main memory for no reason.)</p>
</li>
<li><p>After a thread is created, it must perform an <em>assign</em> or <em>load</em> operation on a variable before performing a <em>use</em> or <em>store</em> operation on that variable. (Less formally: a new thread starts with an empty working memory.)</p>
</li>
<li><p>After a variable is created, every thread must perform an <em>assign</em> or <em>load</em> operation on that variable before performing a <em>use</em> or <em>store</em> operation on that variable. (Less formally: a new variable is created only in main memory and is not initially in any thread’s working memory.)</p>
</li>
</ul>
<p>Provided that all the constraints in Sections <a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/specs/jvms/se6/html/Threads.doc.html#22227">8.3</a>, <a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/specs/jvms/se6/html/Threads.doc.html#22253">8.6</a>, and <a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/specs/jvms/se6/html/Threads.doc.html#22258">8.7</a> are obeyed, a <em>load</em> or <em>store</em> operation may be issued at any time by any thread on any variable, at the whim of the implementation.</p>
<p>There are also certain constraints on the <em>read</em> and <em>write</em> operations performed by main memory:</p>
<ul>
<li><p>For every <em>load</em> operation performed by any thread <em>T</em> on its working copy of a variable <em>V</em>, there must be a corresponding preceding <em>read</em> operation by the main memory on the master copy of <em>V</em>, and the <em>load</em> operation must put into the working copy the data transmitted by the corresponding <em>read</em> operation.</p>
</li>
<li><p>For every <em>store</em> operation performed by any thread <em>T</em> on its working copy of a variable <em>V</em>, there must follow a corresponding <em>write</em> operation by the main memory on the master copy of <em>V</em>, and the <em>write</em> operation must put into the master copy the data transmitted by the corresponding <em>store</em> operation.</p>
</li>
<li><p>Let action <em>A</em> be a <em>load</em> or <em>store</em> by thread <em>T</em> on variable <em>V</em>, and let action <em>P</em> be the corresponding <em>read</em> or <em>write</em> by the main memory on variable <em>V</em>. Similarly, let action <em>B</em> be some other <em>load</em> or <em>store</em> by thread <em>T</em> on that same variable <em>V</em>, and let action <em>Q</em> be the corresponding <em>read</em> or <em>write</em> by the main memory on variable <em>V</em>. If <em>A</em> precedes <em>B</em>, then <em>P</em> must precede <em>Q</em>. (Less formally: operations on the master copy of any given variable on behalf of a thread are performed by the main memory in exactly the order that the thread requested.)</p>
</li>
</ul>
<p>Note that this last rule applies <em>only</em> to actions by a thread on the <em>same</em> variable. However, there is a more stringent rule for <code>volatile</code> variables <a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/specs/jvms/se6/html/Threads.doc.html#22258">(§8.7)</a>.</p>
<hr>
<h2 id="8-4-Nonatomic-Treatment-of-double-and-long-Variables"><a href="#8-4-Nonatomic-Treatment-of-double-and-long-Variables" class="headerlink" title="8.4 Nonatomic Treatment of double and long Variables"></a>8.4 Nonatomic Treatment of <code>double</code> and <code>long</code> Variables</h2><p>If a <code>double</code> or <code>long</code> variable is not declared <code>volatile</code>, then for the purposes of <em>load</em>, <em>store</em>, <em>read</em>, and <em>write</em> operations it is treated as if it were two variables of 32 bits each; wherever the rules require one of these operations, two such operations are performed, one for each 32-bit half. The manner in which the 64 bits of a <code>double</code> or <code>long</code> variable are encoded into two 32-bit quantities and the order of the operations on the halves of the variables are not defined by <em>The Java</em> <em>Language Specification</em>. </p>
<p>This matters only because a <em>read</em> or <em>write</em> of a <code>double</code> or <code>long</code> variable may be handled by an actual main memory as two 32-bit <em>read</em> or <em>write</em> operations that may be separated in time, with other operations coming between them. Consequently, if two threads concurrently assign distinct values to the same shared non-<code>volatile</code> <code>double</code> or <code>long</code> variable, a subsequent use of that variable may obtain a value that is not equal to either of the assigned values, but rather some implementation-dependent mixture of the two values.</p>
<p>An implementation is free to implement <em>load</em>, <em>store</em>, <em>read</em>, and <em>write</em> operations for <code>double</code> and <code>long</code> values as atomic 64-bit operations; in fact, this is strongly encouraged. The model divides them into 32-bit halves for the sake of currently popular microprocessors that fail to provide efficient atomic memory transactions on 64-bit quantities. It would have been simpler for the Java virtual machine to define all memory transactions on single variables as atomic; this more complex definition is a pragmatic concession to current hardware practice. In the future this concession may be eliminated. Meanwhile, programmers are cautioned to explicitly synchronize access to shared <code>double</code> and <code>long</code> variables.</p>
<hr>
<h2 id="8-5-Rules-About-Locks"><a href="#8-5-Rules-About-Locks" class="headerlink" title="8.5 Rules About Locks"></a>8.5 Rules About Locks</h2><p>Let <em>T</em> be a thread and <em>L</em> be a lock. There are certain constraints on the operations performed by <em>T</em> with respect to <em>L</em>:</p>
<ul>
<li><p>A <em>lock</em> operation by <em>T</em> on <em>L</em> may occur only if, for every thread <em>S</em> other than <em>T</em>, the number of preceding <em>unlock</em> operations by <em>S</em> on <em>L</em> equals the number of preceding <em>lock</em> operations by <em>S</em> on <em>L</em>. (Less formally: only one thread at a time is permitted to lay claim to a lock; moreover, a thread may acquire the same lock multiple times and does not relinquish ownership of it until a matching number of <em>unlock</em> operations have been performed.)</p>
</li>
<li><p>An <em>unlock</em> operation by thread <em>T</em> on lock <em>L</em> may occur only if the number of preceding <em>unlock</em> operations by <em>T</em> on <em>L</em> is strictly less than the number of preceding <em>lock</em> operations by <em>T</em> on <em>L</em>. (Less formally: a thread is not permitted to unlock a lock it does not own.)</p>
</li>
</ul>
<p>With respect to a lock, the <em>lock</em> and <em>unlock</em> operations performed by all the threads are performed in some total sequential order. This total order must be consistent with the total order on the operations of each thread.</p>
<hr>
<h2 id="8-6-Rules-About-the-Interaction-of-Locks-and-Variables"><a href="#8-6-Rules-About-the-Interaction-of-Locks-and-Variables" class="headerlink" title="8.6 Rules About the Interaction of Locks and Variables"></a>8.6 Rules About the Interaction of Locks and Variables</h2><p>Let <em>T</em> be any thread, let <em>V</em> be any variable, and let <em>L</em> be any lock. There are certain constraints on the operations performed by <em>T</em> with respect to <em>V</em> and <em>L</em>:</p>
<ul>
<li><p>Between an <em>assign</em> operation by <em>T</em> on <em>V</em> and a subsequent <em>unlock</em> operation by <em>T</em> on <em>L</em>, a <em>store</em> operation by <em>T</em> on <em>V</em> must intervene; moreover, the <em>write</em> operation corresponding to that <em>store</em> must precede the <em>unlock</em> operation, as seen by main memory. (Less formally: if a thread is to perform an <em>unlock</em> operation on <em>any</em> lock, it must first copy <em>all</em> assigned values in its working memory back out to main memory.)</p>
</li>
<li><p>Between a <em>lock</em> operation by <em>T</em> on <em>L</em> and a subsequent <em>use</em> or <em>store</em> operation by <em>T</em> on a variable <em>V</em>, an <em>assign</em> or <em>load</em> operation on <em>V</em> must intervene; moreover, if it is a <em>load</em> operation, then the <em>read</em> operation corresponding to that <em>load</em> must follow the <em>lock</em> operation, as seen by main memory. (Less formally: a <em>lock</em> operation behaves as if it flushes <em>all</em> variables from the thread’s working memory, after which the thread must either assign them itself or load copies anew from main memory.)</p>
</li>
</ul>
<hr>
<h2 id="8-7-Rules-for-volatile-Variables"><a href="#8-7-Rules-for-volatile-Variables" class="headerlink" title="8.7 Rules for volatile Variables"></a>8.7 Rules for <code>volatile</code> Variables</h2><p>If a variable is declared volatile, then additional constraints apply to the operations of each thread. Let <em>T</em> be a thread and let <em>V</em> and <em>W</em> be volatile variables.</p>
<ul>
<li><p>A <em>use</em> operation by <em>T</em> on <em>V</em> is permitted only if the previous operation by <em>T</em> on <em>V</em> was <em>load</em>, and a <em>load</em> operation by <em>T</em> on <em>V</em> is permitted only if the next operation by <em>T</em> on <em>V</em> is <em>use</em>. The <em>use</em> operation is said to be “associated” with the <em>read</em> operation that corresponds to the <em>load</em>.</p>
</li>
<li><p>A <em>store</em> operation by <em>T</em> on <em>V</em> is permitted only if the previous operation by <em>T</em> on <em>V</em> was <em>assign</em>, and an <em>assign</em> operation by <em>T</em> on <em>V</em> is permitted only if the next operation by <em>T</em> on <em>V</em> is <em>store</em>. The <em>assign</em> operation is said to be “associated” with the <em>write</em> operation that corresponds to the <em>store</em>.</p>
</li>
<li><p>Let action <em>A</em> be a <em>use</em> or <em>assign</em> by thread <em>T</em> on variable <em>V</em>, let action <em>F</em> be the <em>load</em> or <em>store</em> associated with <em>A</em>, and let action <em>P</em> be the <em>read</em> or <em>write</em> of <em>V</em> that corresponds to <em>F</em>. Similarly, let action <em>B</em> be a <em>use</em> or <em>assign</em> by thread _T_on variable <em>W</em>, let action <em>G</em> be the <em>load</em> or <em>store</em> associated with <em>B</em>, and let action <em>Q</em> be the <em>read</em> or <em>write</em> of <em>W</em> that corresponds to <em>G</em>. If <em>A</em> precedes <em>B</em>, then <em>P</em> must precede <em>Q</em>. (Less formally: operations on the master copies of volatile variables on behalf of a thread are performed by the main memory in exactly the order that the thread requested.)</p>
</li>
</ul>
<hr>
<h2 id="8-8-Prescient-Store-Operations"><a href="#8-8-Prescient-Store-Operations" class="headerlink" title="8.8 Prescient Store Operations"></a>8.8 Prescient Store Operations</h2><p>If a variable is not declared <code>volatile</code>, then the rules in the previous sections are relaxed slightly to allow <em>store</em> operations to occur earlier than would otherwise be permitted. The purpose of this relaxation is to allow optimizing compilers to perform certain kinds of code rearrangement that preserve the semantics of properly synchronized programs, but might be caught in the act of performing memory operations out of order by programs that are not properly synchronized.</p>
<p>Suppose that a <em>store</em> by <em>T</em> of <em>V</em> would follow a particular <em>assign</em> by <em>T</em> of <em>V</em> according to the rules of the previous sections, with no intervening <em>load</em> or <em>assign</em> by <em>T</em> of <em>V</em>. Then that <em>store</em> operation would send to the main memory the value that the <em>assign</em> operation put into the working memory of thread <em>T</em>. The special rule allows the <em>store</em> operation actually to occur before the <em>assign</em> operation instead, if the following restrictions are obeyed:</p>
<ul>
<li><p>If the <em>store</em> operation occurs, the <em>assign</em> is bound to occur. (Remember, these are restrictions on what actually happens, not on what a thread plans to do. No fair performing a <em>store</em> and then throwing an exception before the <em>assign</em> occurs!)</p>
</li>
<li><p>No <em>lock</em> operation intervenes between the relocated <em>store</em> and the <em>assign</em>.</p>
</li>
<li><p>No <em>load</em> of <em>V</em> intervenes between the relocated <em>store</em> and the <em>assign</em>.</p>
</li>
<li><p>No other <em>store</em> of <em>V</em> intervenes between the relocated <em>store</em> and the <em>assign</em>.</p>
</li>
<li><p>The <em>store</em> operation sends to the main memory the value that the <em>assign</em> operation will put into the working memory of thread <em>T</em>.</p>
</li>
</ul>
<p> </p>
<p>This last property inspires us to call such an early <em>store</em> operation <em>prescient</em>: it has to know ahead of time, somehow, what value will be stored by the <em>assign</em> that it should have followed. In practice, optimized compiled code will compute such values early (which is permitted if, for example, the computation has no side effects and throws no exceptions), store them early (before entering a loop, for example), and keep them in working registers for later use within the loop.</p>
<hr>
<h2 id="8-9-Discussion"><a href="#8-9-Discussion" class="headerlink" title="8.9 Discussion"></a>8.9 Discussion</h2><p>Any association between locks and variables is purely conventional. Locking any lock conceptually flushes <em>all</em> variables from a thread’s working memory, and unlocking any lock forces the writing out to main memory of _all_variables that the thread has assigned. That a lock may be associated with a particular object or a class is purely a convention. For example, in some applications it may be appropriate always to lock an object before accessing any of its instance variables; <code>synchronized</code> methods are a convenient way to follow this convention. In other applications, it may suffice to use a single lock to synchronize access to a large collection of objects.</p>
<p>If a thread uses a particular shared variable only after locking a particular lock and before the corresponding unlocking of that same lock, then the thread will read the shared value of that variable from main memory after the _lock_operation, if necessary, and will copy back to main memory the value most recently assigned to that variable before the <em>unlock</em> operation. This, in conjunction with the mutual exclusion rules for locks, suffices to guarantee that values are correctly transmitted from one thread to another through shared variables.</p>
<p>The rules for volatile variables effectively require that main memory be touched exactly once for each <em>use</em> or <em>assign</em> of a volatile variable by a thread, and that main memory be touched in exactly the order dictated by the thread execution semantics. However, such memory operations are not ordered with respect to <em>read</em> and <em>write</em> operations on nonvolatile variables.</p>
<hr>
<h2 id="8-10-Example-Possible-Swap"><a href="#8-10-Example-Possible-Swap" class="headerlink" title="8.10 Example: Possible Swap"></a>8.10 Example: Possible Swap</h2><p>Consider a class that has class variables <code>a</code> and <code>b</code> and methods <code>hither</code> and <code>yon</code>:</p>
<blockquote>
<p>class Sample {<br>    int a &#x3D; 1, b &#x3D; 2;<br>    void hither() {<br>        a &#x3D; b;<br>    }<br>    void yon()<br>        b &#x3D; a;<br>    }<br>}</p>
</blockquote>
<p>Now suppose that two threads are created and that one thread calls <code>hither</code> while the other thread calls <code>yon</code>. What is the required set of actions and what are the ordering constraints?</p>
<p>Let us consider the thread that calls <code>hither</code>. According to the rules, this thread must perform a <em>use</em> of <code>b</code> followed by an <em>assign</em> of <code>a</code>. That is the bare minimum required to execute a call to the method <code>hither</code>.</p>
<p>Now, the first operation on variable <code>b</code> by the thread cannot be <em>use</em>. But it may be <em>assign</em> or <em>load</em>. An <em>assign</em> to <code>b</code> cannot occur because the program text does not call for such an <em>assign</em> operation, so a <em>load</em> of <code>b</code> is required. This _load_operation by the thread in turn requires a preceding <em>read</em> operation for <code>b</code> by the main memory.</p>
<p>The thread may optionally <em>store</em> the value of <code>a</code> after the <em>assign</em> has occurred. If it does, then the <em>store</em> operation in turn requires a following <em>write</em> operation for <code>a</code> by the main memory.</p>
<p>The situation for the thread that calls <code>yon</code> is similar, but with the roles of <code>a</code> and <code>b</code> exchanged.</p>
<p>The total set of operations may be pictured as follows:</p>
<p><img src="https://docs.oracle.com/javase/specs/jvms/se6/html/Threads.doc.anc.gif">  </p>
<p>Here an arrow from action <em>A</em> to action <em>B</em> indicates that <em>A</em> must precede <em>B</em>.</p>
<p>In what order may the operations by the main memory occur? The only constraint is that it is not possible both for the <em>write</em> of <code>a</code> to precede the <em>read</em> of <code>a</code> and for the <em>write</em> of <code>b</code> to precede the <em>read</em> of <code>b</code>, because the causality arrows in the diagram would form a loop so that an action would have to precede itself, which is not allowed. Assuming that the optional <em>store</em> and <em>write</em> operations are to occur, there are three possible orderings in which the main memory might legitimately perform its operations. Let <code>ha</code> and <code>hb</code> be the working copies of <code>a</code> and <code>b</code> for the <code>hither</code> thread, let <code>ya</code> and <code>yb</code> be the working copies for the <code>yon</code> thread, and let <code>ma</code> and <code>mb</code> be the master copies in main memory. Initially <code>ma=1</code> and <code>mb=2</code>. Then the three possible orderings of operations and the resulting states are as follows:</p>
<ul>
<li><p><em>write</em> <code>a``![](https://docs.oracle.com/javase/specs/jvms/se6/html/chars/arrwrite.gif)</code><em>read</em> <code>a</code>, <em>read</em> <code>b``![](https://docs.oracle.com/javase/specs/jvms/se6/html/chars/arrwrite.gif)</code><em>write</em> <code>b</code> (then <code>ha=2</code>, <code>hb=2</code>, <code>ma=2</code>, <code>mb=2</code>, <code>ya=2</code>, <code>yb=2</code>)</p>
</li>
<li><p><em>read</em> <code>a``![](https://docs.oracle.com/javase/specs/jvms/se6/html/chars/arrwrite.gif)</code><em>write</em> <code>a</code>, <em>write</em> <code>b``![](https://docs.oracle.com/javase/specs/jvms/se6/html/chars/arrwrite.gif)</code><em>read</em> <code>b</code> (then <code>ha=1</code>, <code>hb=1</code>, <code>ma=1</code>, <code>mb=1</code>, <code>ya=1</code>, <code>yb=1</code>)</p>
</li>
<li><p><em>read</em> <code>a``![](https://docs.oracle.com/javase/specs/jvms/se6/html/chars/arrwrite.gif)</code><em>write</em> <code>a</code>, <em>read</em> <code>b``![](https://docs.oracle.com/javase/specs/jvms/se6/html/chars/arrwrite.gif)</code><em>write</em> <code>b</code> (then <code>ha=2</code>, <code>hb=2</code>, <code>ma=2</code>, <code>mb=1</code>, <code>ya=1</code>, <code>yb=1</code>)</p>
</li>
</ul>
<p>Thus, the net result might be that, in main memory, <code>b</code> is copied into <code>a</code>, <code>a</code> is copied into <code>b</code>, or the values of <code>a</code> and <code>b</code> are swapped; moreover, the working copies of the variables might or might not agree. It would be incorrect, of course, to assume that any one of these outcomes is more likely than another. This is one place in which the behavior of a program is necessarily timing-dependent.</p>
<p>Of course, an implementation might also choose not to perform the <em>store</em> and <em>write</em> operations, or only one of the two pairs, leading to yet other possible results.</p>
<p>Now suppose that we modify the example to use <code>synchronized</code> methods:</p>
<blockquote>
<p>class SynchSample {<br>    int a &#x3D; 1, b &#x3D; 2;<br>    synchronized void hither() {<br>        a &#x3D; b;<br>    }<br>    synchronized void yon()<br>        b &#x3D; a;<br>    }<br>}</p>
</blockquote>
<p>Let us again consider the thread that calls <code>hither</code>. According to the rules, this thread must perform a <em>lock</em> operation (on the instance of class <code>SynchSample</code> on which the <code>hither</code> method is being called) before the body of method <code>hither</code> is executed. This is followed by a <em>use</em> of <code>b</code> and then an <em>assign</em> of <code>a</code>. Finally, an <em>unlock</em> operation on that same instance of <code>SynchSample</code> must be performed after the body of method <code>hither</code> completes. That is the bare minimum required to execute a call to the method <code>hither</code>.</p>
<p>As before, a <em>load</em> of <code>b</code> is required, which in turn requires a preceding <em>read</em> operation for <code>b</code> by the main memory. Because the <em>load</em> follows the <em>lock</em> operation, the corresponding <em>read</em> must also follow the <em>lock</em> operation.</p>
<p>Because an <em>unlock</em> operation follows the <em>assign</em> of <code>a</code>, a <em>store</em> operation on <code>a</code> is mandatory, which in turn requires a following <em>write</em> operation for <code>a</code> by the main memory. The <em>write</em> must precede the <em>unlock</em> operation.</p>
<p>The situation for the thread that calls <code>yon</code> is similar, but with the roles of <code>a</code> and <code>b</code> exchanged.</p>
<p>The total set of operations may be pictured as follows:</p>
<p><img src="https://docs.oracle.com/javase/specs/jvms/se6/html/Threads.doc.anc1.gif">  </p>
<p>The <em>lock</em> and <em>unlock</em> operations provide further constraints on the order of operations by the main memory; the <em>lock</em> operation by one thread cannot occur between the <em>lock</em> and <em>unlock</em> operations of the other thread. Moreover, the <em>unlock</em> operations require that the <em>store</em> and <em>write</em> operations occur. It follows that only two sequences are possible:</p>
<ul>
<li><p><em>write</em> <code>a``![](https://docs.oracle.com/javase/specs/jvms/se6/html/chars/arrwrite.gif)</code><em>read</em> <code>a</code>, <em>read</em> <code>b``![](https://docs.oracle.com/javase/specs/jvms/se6/html/chars/arrwrite.gif)</code><em>write</em> <code>b</code> (then <code>ha=2</code>, <code>hb=2</code>, <code>ma=2</code>, <code>mb=2</code>, <code>ya=2</code>, <code>yb=2</code>)</p>
</li>
<li><p><em>read</em> <code>a``![](https://docs.oracle.com/javase/specs/jvms/se6/html/chars/arrwrite.gif)</code><em>write</em> <code>a</code>, <em>write</em> <code>b``![](https://docs.oracle.com/javase/specs/jvms/se6/html/chars/arrwrite.gif)</code><em>read</em> <code>b</code> (then <code>ha=1</code>, <code>hb=1</code>, <code>ma=1</code>, <code>mb=1</code>, <code>ya=1</code>, <code>yb=1</code>)</p>
</li>
</ul>
<p>While the resulting state is timing-dependent, it can be seen that the two threads will necessarily agree on the values of <code>a</code> and <code>b</code>.</p>
<hr>
<h2 id="8-11-Example-Out-of-Order-Writes"><a href="#8-11-Example-Out-of-Order-Writes" class="headerlink" title="8.11 Example: Out-of-Order Writes"></a>8.11 Example: Out-of-Order Writes</h2><p>This example is similar to that in the preceding section, except that one method assigns to both variables and the other method reads both variables. Consider a class that has class variables <code>a</code> and <code>b</code> and methods <code>to</code> and <code>fro</code>:</p>
<blockquote>
<p>class Simple {<br>    int a &#x3D; 1, b &#x3D; 2;<br>    void to() {<br>        a &#x3D; 3;<br>        b &#x3D; 4;<br>    }<br>    void fro()<br>        System.out.println(“a&#x3D; “ + a + “, b&#x3D;” + b);<br>    }<br>}</p>
</blockquote>
<p>Now suppose that two threads are created and that one thread calls <code>to</code> while the other thread calls <code>fro</code>. What is the required set of actions and what are the ordering constraints?</p>
<p>Let us consider the thread that calls <code>to</code>. According to the rules, this thread must perform an <em>assign</em> of <code>a</code> followed by an <em>assign</em> of <code>b</code>. That is the bare minimum required to execute a call to the method <code>to</code>. Because there is no synchronization, it is at the option of the implementation whether or not to <em>store</em> the assigned values back to main memory! Therefore, the thread that calls <code>fro</code> may obtain either <code>1</code> or <code>3</code> for the value of <code>a</code> and independently may obtain either <code>2</code> or <code>4</code> for the value of <code>b</code>.</p>
<p>Now suppose that <code>to</code> is <code>synchronized</code> but <code>fro</code> is not:</p>
<blockquote>
<p>class SynchSimple {<br>    int a &#x3D; 1, b &#x3D; 2;<br>    synchronized void to() {<br>        a &#x3D; 3;<br>        b &#x3D; 4;<br>    }<br>    void fro()<br>        System.out.println(“a&#x3D; “ + a + “, b&#x3D;” + b);<br>    }<br>}</p>
</blockquote>
<p>In this case the method <code>to</code> will be forced to <em>store</em> the assigned values back to main memory before the <em>unlock</em> operation at the end of the method. The method <code>fro</code> must, of course, use <code>a</code> and <code>b</code> (in that order) and so must <em>load</em> values for <code>a</code> and <code>b</code> from main memory.</p>
<p>The total set of operations may be pictured as follows:  </p>
<p><img src="https://docs.oracle.com/javase/specs/jvms/se6/html/Threads.doc.anc2.gif">  </p>
<p>Here an arrow from action <em>A</em> to action <em>B</em> indicates that <em>A</em> must precede <em>B</em>.</p>
<p>In what order may the operations by the main memory occur? Note that the rules do not require that <em>write</em> <code>a</code> occur before <em>write</em> <code>b</code>; neither do they require that <em>read</em> <code>a</code> occur before <em>read</em> <code>b</code>. Also, even though method <code>to</code> is synchronized, method <code>fro</code> is not synchronized, so there is nothing to prevent the <em>read</em> operations from occurring between the <em>lock</em> and <em>unlock</em> operations. (The point is that declaring one method <code>synchronized</code> does not of itself make that method behave as if it were atomic.)</p>
<p>As a result, the method <code>fro</code> could still obtain either <code>1</code> or <code>3</code> for the value of <code>a</code> and independently could obtain either <code>2</code> or <code>4</code> for the value of <code>b</code>. In particular, <code>fro</code> might observe the value <code>1</code> for <code>a</code> and <code>4</code> for <code>b</code>. Thus, even though <code>to</code> does an <em>assign</em> to <code>a</code> and then an <em>assign</em> to <code>b</code>, the <em>write</em> operations to main memory may be observed by another thread to occur as if in the opposite order. </p>
<p>Finally, suppose that <code>to</code> and <code>fro</code> are both <code>synchronized</code>:</p>
<blockquote>
<p>class SynchSynchSimple {<br>    int a &#x3D; 1, b &#x3D; 2;<br>    synchronized void to() {<br>        a &#x3D; 3;<br>        b &#x3D; 4;<br>    }<br>    synchronized void fro()<br>        System.out.println(“a&#x3D; “ + a + “, b&#x3D;” + b);<br>    }<br>}</p>
</blockquote>
<p>In this case, the actions of method <code>fro</code> cannot be interleaved with the actions of method <code>to</code>, and so <code>fro</code> will print either “<code>a=1, b=2</code>“ or “<code>a=3, b=4</code>“.</p>
<hr>
<h2 id="8-12-Threads"><a href="#8-12-Threads" class="headerlink" title="8.12 Threads"></a>8.12 Threads</h2><p>Threads are created and managed by the classes <code>Thread</code> and <code>ThreadGroup</code>. Creating a <code>Thread</code> object creates a thread, and that is the only way to create a thread. When the thread is created, it is not yet active; it begins to run when its <code>start</code> method is called.</p>
<hr>
<h2 id="8-13-Locks-and-Synchronization"><a href="#8-13-Locks-and-Synchronization" class="headerlink" title="8.13 Locks and Synchronization"></a>8.13 Locks and Synchronization</h2><p>There is a lock associated with every object. The Java programming language does not provide a way to perform separate <em>lock</em> and <em>unlock</em> operations; instead, they are implicitly performed by high-level constructs that always arrange to pair such operations correctly. (The Java virtual machine, however, provides separate <em>monitorenter</em> and <em>monitorexit</em> instructions that implement the <em>lock</em> and <em>unlock</em> operations.)</p>
<p>The <code>synchronized</code> statement computes a reference to an object; it then attempts to perform a <em>lock</em> operation on that object and does not proceed further until the <em>lock</em> operation has successfully completed. (A <em>lock</em> operation may be delayed because the rules about locks can prevent the main memory from participating until some other thread is ready to perform one or more <em>unlock</em> operations.) After the lock operation has been performed, the body of the <code>synchronized</code> statement is executed. Normally, a compiler for the Java programming language ensures that the <em>lock</em> operation implemented by a <em>monitorenter</em> instruction executed prior to the execution of the body of the <code>synchronized</code> statement is matched by an unlock operation implemented by a <em>monitorexit</em> instruction whenever the <code>synchronized</code> statement completes, whether completion is normal or abrupt.</p>
<p>A <code>synchronized</code> method automatically performs a <em>lock</em> operation when it is invoked; its body is not executed until the <em>lock</em> operation has successfully completed. If the method is an instance method, it locks the lock associated with the instance for which it was invoked (that is, the object that will be known as <code>this</code> during execution of the method’s body). If the method is <code>static</code>, it locks the lock associated with the <code>Class</code> object that represents the class in which the method is defined. If execution of the method’s body is ever completed, either normally or abruptly, an <em>unlock</em> operation is automatically performed on that same lock.</p>
<p>Best practice is that if a variable is ever to be assigned by one thread and used or assigned by another, then all accesses to that variable should be enclosed in <code>synchronized</code> methods or <code>synchronized</code> statements.</p>
<p>Although a compiler for the Java programming language normally guarantees structured use of locks (see <a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/specs/jvms/se6/html/Compiling.doc.html#6530">Section 7.14, “Synchronization”</a>), there is no assurance that all code submitted to the Java virtual machine will obey this property. Implementations of the Java virtual machine are permitted but not required to enforce both of the following two rules guaranteeing structured locking.</p>
<p>Let <em>T</em> be a thread and <em>L</em> be a lock. Then:</p>
<ol start="2">
<li><p>The number of <em>lock</em> operations performed by <em>T</em> on <em>L</em> during a method invocation must equal the number of <em>unlock</em> operations performed by <em>T</em> on <em>L</em> during the method invocation whether the method invocation completes normally or abruptly. </p>
</li>
<li><p>At no point during a method invocation may the number of <em>unlock</em> operations performed by <em>T</em> on <em>L</em> since the method invocation exceed the number of <em>lock</em> operations performed by <em>T</em> on <em>L</em> since the method invocation.</p>
</li>
</ol>
<p>In less formal terms, during a method invocation every <em>unlock</em> operation on <em>L</em> must match some preceding <em>lock</em> operation on <em>L</em>. </p>
<p>Note that the locking and unlocking automatically performed by the Java virtual machine when invoking a synchronized method are considered to occur during the calling method’s invocation.</p>
<hr>
<h2 id="8-14-Wait-Sets-and-Notification"><a href="#8-14-Wait-Sets-and-Notification" class="headerlink" title="8.14 Wait Sets and Notification"></a>8.14 Wait Sets and Notification</h2><p>Every object, in addition to having an associated lock, has an associated wait set, which is a set of threads. When an object is first created, its wait set is empty.</p>
<p>Wait sets are used by the methods <code>wait</code>, <code>notify</code>, and <code>notifyAll</code> of class <code>Object</code>. These methods also interact with the scheduling mechanism for threads.</p>
<p>The method <code>wait</code> should be invoked for an object only when the current thread (call it <em>T</em>  ) has already locked the object’s lock. Suppose that thread <em>T</em> has in fact performed <em>N</em> <em>lock</em> operations on the object that have not been matched by <em>unlock</em> operations on that same object. The <code>wait</code> method then adds the current thread to the wait set for the object, disables the current thread for thread scheduling purposes, and performs <em>N</em> <em>unlock</em> operations on the object to relinquish the lock on it. Locks having been locked by thread <em>T</em> on objects other than the one <em>T</em> is to wait on are not relinquished. The thread <em>T</em> then lies dormant until one of three things happens:</p>
<ul>
<li><p>Some other thread invokes the <code>notify</code> method for that object, and thread <em>T</em> happens to be the one arbitrarily chosen as the one to notify.</p>
</li>
<li><p>Some other thread invokes the <code>notifyAll</code> method for that object.</p>
</li>
<li><p>If the call by thread <em>T</em> to the <code>wait</code> method specified a time-out interval, then the specified amount of real time elapses.</p>
</li>
</ul>
<p>The thread <em>T</em> is then removed from the wait set and reenabled for thread scheduling. It then locks the object again (which may involve competing in the usual manner with other threads); once it has gained control of the lock, it performs <em>N</em> - <em>1</em> additional <em>lock</em> operations on that same object and then returns from the invocation of the <code>wait</code> method. Thus, on return from the <code>wait</code> method, the state of the object’s lock is exactly as it was when the <code>wait</code> method was invoked.</p>
<p>The <code>notify</code> method should be invoked for an object only when the current thread has already locked the object’s lock, or an <code>IllegalMonitorStateException</code> will be thrown. If the wait set for the object is not empty, then some arbitrarily chosen thread is removed from the wait set and reenabled for thread scheduling. (Of course, that thread will not be able to proceed until the current thread relinquishes the object’s lock.)</p>
<p>The <code>notifyAll</code> method should be invoked for an object only when the current thread has already locked the object’s lock, or an <code>IllegalMonitorStateException</code> will be thrown. Every thread in the wait set for the object is removed from the wait set and reenabled for thread scheduling. (Those threads will not be able to proceed until the current thread relinquishes the object’s lock.)</p>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/2022/09/28/HotSpot%E5%AD%97%E8%8A%82%E7%A0%81%E8%A7%A3%E9%87%8A%E5%99%A8%E7%89%87%E6%AE%B5/" title="HotSpot字节码解释器片段"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">上一页: HotSpot字节码解释器片段</span></a><a class="button is-default" href="/2022/09/02/jvm-spec-3.%20Compiling%20for%20the%20Java%20Virtual%20Machine/" title="jvm-spec-3. Compiling for the Java Virtual Machine"><span class="has-text-weight-semibold">下一页: jvm-spec-3. Compiling for the Java Virtual Machine</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="Zhangdd/Claudia-theme-blog" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/wwinter117"><i class="iconfont icon-github"></i></a><!-- Ins--><!-- RSS--><a title="rss" target="_blank" rel="noopener nofollow" href="/atom.xml"><i class="iconfont icon-rss"></i></a><!-- 知乎--><!-- 领英--><!-- 脸书--></section><p><span>Copyright ©</span><span> Zhangdd 2021 - 2024</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="site author" target="_blank" rel="noopener" href="//github.com/wwinter117">Hosted by Zhangdd&nbsp;</a></p><!--div(style="margin-top: 2px")--><!--  a(title="github-button" class="github-button" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true")--></div><div><span>浙备7837-534598</span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/jquery-3.6.1.min.js"></script><script src="/js/jquery-fancybox.min.js"></script><script src="/js/img_zoom.js"></script><script src="/js/post.js"></script></body></html>